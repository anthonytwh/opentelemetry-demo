apiVersion: v1
kind: Namespace
metadata:
  name: otel
  labels:
    name: otel
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: accountingservice
  name: accountingservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: accountingservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: accountingservice
    spec:
      containers:
        - env:
            - name: KAFKA_SERVICE_ADDR
              value: kafka-headless:9092
            - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: accountingservice
          image: ghcr.io/open-telemetry/demo:1.3.1-accountingservice
          name: accounting-service
          resources:
            limits:
              memory: "20971520"
      restartPolicy: Always
status: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: adservice
  name: adservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: adservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: adservice
    spec:
      containers:
        - env:
            - name: AD_SERVICE_PORT
              value: "9555"
            - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
              value: featureflagservice:50053
            - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: adservice
          image: ghcr.io/open-telemetry/demo:1.3.1-adservice
          name: ad-service
          ports:
            - containerPort: 9555
          resources:
            limits:
              memory: "314572800"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: adservice
  name: adservice
spec:
  ports:
    - name: "9555"
      port: 9555
      targetPort: 9555
  selector:
    io.kompose.service: adservice
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: cartservice
  name: cartservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: cartservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: cartservice
    spec:
      containers:
        - env:
            - name: ASPNETCORE_URLS
              value: http://*:7070
            - name: CART_SERVICE_PORT
              value: "7070"
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: cartservice
            - name: REDIS_ADDR
              value: redis-cart:6379
          image: ghcr.io/open-telemetry/demo:1.3.1-cartservice
          name: cart-service
          ports:
            - containerPort: 7070
          resources:
            limits:
              memory: "167772160"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: cartservice
  name: cartservice
spec:
  ports:
    - name: "7070"
      port: 7070
      targetPort: 7070
  selector:
    io.kompose.service: cartservice
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: checkoutservice
  name: checkoutservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: checkoutservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: checkoutservice
    spec:
      containers:
        - env:
            - name: CART_SERVICE_ADDR
              value: cartservice:7070
            - name: CHECKOUT_SERVICE_PORT
              value: "5050"
            - name: CURRENCY_SERVICE_ADDR
              value: currencyservice:7001
            - name: EMAIL_SERVICE_ADDR
              value: http://emailservice:6060
            - name: KAFKA_SERVICE_ADDR
              value: kafka-headless:9092
            - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: checkoutservice
            - name: PAYMENT_SERVICE_ADDR
              value: paymentservice:50051
            - name: PRODUCT_CATALOG_SERVICE_ADDR
              value: productcatalogservice:3550
            - name: SHIPPING_SERVICE_ADDR
              value: shippingservice:50050
          image: ghcr.io/open-telemetry/demo:1.3.1-checkoutservice
          name: checkout-service
          ports:
            - containerPort: 5050
          resources:
            limits:
              memory: "20971520"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: checkoutservice
  name: checkoutservice
spec:
  ports:
    - name: "5050"
      port: 5050
      targetPort: 5050
  selector:
    io.kompose.service: checkoutservice
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: currencyservice
  name: currencyservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: currencyservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: currencyservice
    spec:
      containers:
        - env:
            - name: CURRENCY_SERVICE_PORT
              value: "7001"
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo,service.name=currencyservice
          image: ghcr.io/open-telemetry/demo:1.3.1-currencyservice
          name: currency-service
          ports:
            - containerPort: 7001
          resources:
            limits:
              memory: "20971520"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: currencyservice
  name: currencyservice
spec:
  ports:
    - name: "7001"
      port: 7001
      targetPort: 7001
  selector:
    io.kompose.service: currencyservice
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: emailservice
  name: emailservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: emailservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: emailservice
    spec:
      containers:
        - env:
            - name: APP_ENV
              value: production
            - name: EMAIL_SERVICE_PORT
              value: "6060"
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4318/v1/traces
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: emailservice
          image: ghcr.io/open-telemetry/demo:1.3.1-emailservice
          name: email-service
          ports:
            - containerPort: 6060
          resources:
            limits:
              memory: "104857600"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: emailservice
  name: emailservice
spec:
  ports:
    - name: "6060"
      port: 6060
      targetPort: 6060
  selector:
    io.kompose.service: emailservice
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: featureflagservice
  name: featureflagservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: featureflagservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: featureflagservice
    spec:
      containers:
        - env:
            - name: DATABASE_URL
              value: ecto://ffs:ffs@ffs-postgres:5432/ffs
            - name: FEATURE_FLAG_GRPC_SERVICE_PORT
              value: "50053"
            - name: FEATURE_FLAG_SERVICE_PATH_ROOT
              value: '"/feature"'
            - name: FEATURE_FLAG_SERVICE_PORT
              value: "8081"
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_TRACES_PROTOCOL
              value: grpc
            - name: OTEL_SERVICE_NAME
              value: featureflagservice
          image: ghcr.io/open-telemetry/demo:1.3.1-featureflagservice
          livenessProbe:
            exec:
              command: ['curl', '-fsS', '-o', '/dev/null', 'http://localhost:8081']
          name: feature-flag-service
          ports:
            - containerPort: 8081
            - containerPort: 50053
          resources:
            limits:
              memory: "183500800"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: featureflagservice
  name: featureflagservice
spec:
  ports:
    - name: "8081"
      port: 8081
      targetPort: 8081
    - name: "50053"
      port: 50053
      targetPort: 50053
  selector:
    io.kompose.service: featureflagservice
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: ffs-postgres
  name: ffs-postgres
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: ffs-postgres
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: ffs-postgres
    spec:
      containers:
        - env:
            - name: POSTGRES_DB
              value: ffs
            - name: POSTGRES_PASSWORD
              value: ffs
            - name: POSTGRES_USER
              value: ffs
          image: postgres:14
          livenessProbe:
            exec:
              command:
                - sh
                - -c
                - pg_isready -d ffs -U ffs
            failureThreshold: 5
            periodSeconds: 10
            timeoutSeconds: 5
          name: postgres
          ports:
            - containerPort: 5432
          resources:
            limits:
              memory: "125829120"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: ffs-postgres
  name: ffs-postgres
spec:
  ports:
    - name: "5432"
      port: 5432
      targetPort: 5432
  selector:
    io.kompose.service: ffs-postgres
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: frauddetectionservice
  name: frauddetectionservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: frauddetectionservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: frauddetectionservice
    spec:
      containers:
        - env:
            - name: KAFKA_SERVICE_ADDR
              value: kafka-headless:9092
            - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: frauddetectionservice
          image: ghcr.io/open-telemetry/demo:1.3.1-frauddetectionservice
          name: frauddetection-service
          resources:
            limits:
              memory: "209715200"
      restartPolicy: Always
status: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: frontend
  name: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: frontend
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: frontend
    spec:
      containers:
        - env:
            - name: AD_SERVICE_ADDR
              value: adservice:9555
            - name: CART_SERVICE_ADDR
              value: cartservice:7070
            - name: CHECKOUT_SERVICE_ADDR
              value: checkoutservice:5050
            - name: CURRENCY_SERVICE_ADDR
              value: currencyservice:7001
            - name: ENV_PLATFORM
              value: local
            - name: FRONTEND_ADDR
              value: frontend:8080
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: frontend
            - name: PORT
              value: "8080"
            - name: PRODUCT_CATALOG_SERVICE_ADDR
              value: productcatalogservice:3550
            - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://localhost:4318/v1/traces
            - name: RECOMMENDATION_SERVICE_ADDR
              value: recommendationservice:9001
            - name: SHIPPING_SERVICE_ADDR
              value: shippingservice:50050
            - name: WEB_OTEL_SERVICE_NAME
              value: frontend-web
          image: ghcr.io/open-telemetry/demo:1.3.1-frontend
          name: frontend
          ports:
            - containerPort: 8080
          resources:
            limits:
              memory: "209715200"
      restartPolicy: Always
status: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: frontendproxy
  name: frontendproxy
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: frontendproxy
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: frontendproxy
    spec:
      containers:
        - env:
            - name: ENVOY_PORT
              value: "8080"
            - name: FEATURE_FLAG_SERVICE_HOST
              value: feature-flag-service
            - name: FEATURE_FLAG_SERVICE_PORT
              value: "8081"
            - name: FRONTEND_HOST
              value: frontend
            - name: FRONTEND_PORT
              value: "8080"
            - name: GRAFANA_SERVICE_HOST
              value: grafana
            - name: GRAFANA_SERVICE_PORT
              value: "3000"
            - name: JAEGER_SERVICE_HOST
              value: jaeger
            - name: JAEGER_SERVICE_PORT
              value: "16686"
            - name: LOCUST_WEB_HOST
              value: loadgenerator
            - name: LOCUST_WEB_PORT
              value: "8089"
            - name: OTEL_COLLECTOR_HOST
              value: otelcol
            - name: OTEL_COLLECTOR_PORT
              value: "4317"
          image: ghcr.io/open-telemetry/demo:1.3.1-frontendproxy
          name: frontend-proxy
          ports:
            - containerPort: 8080
            - containerPort: 10000
          resources:
            limits:
              memory: "52428800"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: frontendproxy
  name: frontendproxy
spec:
  ports:
    - name: "8080"
      port: 8080
      targetPort: 8080
    - name: "10000"
      port: 10000
      targetPort: 10000
  selector:
    io.kompose.service: frontendproxy
status:
  loadBalancer: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: frontend
  name: frontend
spec:
  ports:
    - name: "8080"
      port: 8080
      targetPort: 8080
  selector:
    io.kompose.service: frontend
status:
  loadBalancer: {}
---
apiVersion: v1
data:
  grafana.ini: "# Copyright The OpenTelemetry Authors\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n##################### Grafana Configuration Example #####################\n#\n# Everything has defaults so you only need to uncomment things you want to\n# change\n\n# possible values : production, development\n;app_mode = production\n\n# instance name, defaults to HOSTNAME environment variable value or hostname if HOSTNAME var is empty\n;instance_name = ${HOSTNAME}\n\n# force migration will run migrations that might cause dataloss\n;force_migration = false\n\n#################################### Paths ####################################\n[paths]\n# Path to where grafana can store temp files, sessions, and the sqlite3 db (if that is used)\n;data = /var/lib/grafana\n\n# Temporary files in `data` directory older than given duration will be removed\n;temp_data_lifetime = 24h\n\n# Directory where grafana can store logs\n;logs = /var/log/grafana\n\n# Directory where grafana will automatically scan and look for plugins\n;plugins = /var/lib/grafana/plugins\n\n# folder that contains provisioning config files that grafana will apply on startup and while running.\nprovisioning = /etc/grafana/provisioning\n\n#################################### Server ####################################\n[server]\n# Protocol (http, https, h2, socket)\nprotocol = http\n\n# The ip address to bind to, empty will bind to all interfaces\n;http_addr =\n\n# The http port  to use\nhttp_port = 3000\n\n# The public facing domain name used to access grafana from a browser\ndomain = localhost\n\n# Redirect to correct domain if host header does not match domain\n# Prevents DNS rebinding attacks\n;enforce_domain = false\n\n# The full public facing url you use in browser, used for redirects and emails\n# If you use reverse proxy and sub path specify full url (with sub path)\nroot_url = %(protocol)s://%(domain)s/grafana/\n\n# Serve Grafana from subpath specified in `root_url` setting. By default it is set to `false` for compatibility reasons.\nserve_from_sub_path = true\n\n# Log web requests\n;router_logging = false\n\n# the path relative working path\n;static_root_path = public\n\n# enable gzip\n;enable_gzip = false\n\n# https certs & key file\n;cert_file =\n;cert_key =\n\n# Unix socket path\n;socket =\n\n# CDN Url\n;cdn_url =\n\n# Sets the maximum time using a duration format (5s/5m/5ms) before timing out read of an incoming request and closing idle connections.\n# `0` means there is no timeout for reading the request.\n;read_timeout = 0\n\n#################################### Database ####################################\n[database]\n# You can configure the database connection by specifying type, host, name, user and password\n# as separate properties or as on string using the url properties.\n\n# Either \"mysql\", \"postgres\" or \"sqlite3\", it's your choice\n;type = sqlite3\n;host = 127.0.0.1:3306\n;name = grafana\n;user = root\n# If the password contains # or ; you have to wrap it with triple quotes. Ex \"\"\"#password;\"\"\"\n;password =\n\n# Use either URL or the previous fields to configure the database\n# Example: mysql://user:secret@host:port/database\n;url =\n\n# For \"postgres\" only, either \"disable\", \"require\" or \"verify-full\"\n;ssl_mode = disable\n\n# Database drivers may support different transaction isolation levels.\n# Currently, only \"mysql\" driver supports isolation levels.\n# If the value is empty - driver's default isolation level is applied.\n# For \"mysql\" use \"READ-UNCOMMITTED\", \"READ-COMMITTED\", \"REPEATABLE-READ\" or \"SERIALIZABLE\".\n;isolation_level =\n\n;ca_cert_path =\n;client_key_path =\n;client_cert_path =\n;server_cert_name =\n\n# For \"sqlite3\" only, path relative to data_path setting\n;path = grafana.db\n\n# Max idle conn setting default is 2\n;max_idle_conn = 2\n\n# Max conn setting default is 0 (mean not set)\n;max_open_conn =\n\n# Connection Max Lifetime default is 14400 (means 14400 seconds or 4 hours)\n;conn_max_lifetime = 14400\n\n# Set to true to log the sql calls and execution times.\n;log_queries =\n\n# For \"sqlite3\" only. cache mode setting used for connecting to the database. (private, shared)\n;cache_mode = private\n\n# For \"mysql\" only if lockingMigration feature toggle is set. How many seconds to wait before failing to lock the database for the migrations, default is 0.\n;locking_attempt_timeout_sec = 0\n\n################################### Data sources #########################\n[datasources]\n# Upper limit of data sources that Grafana will return. This limit is a temporary configuration and it will be deprecated when pagination will be introduced on the list data sources API.\n;datasource_limit = 5000\n\n#################################### Cache server #############################\n[remote_cache]\n# Either \"redis\", \"memcached\" or \"database\" default is \"database\"\n;type = database\n\n# cache connectionstring options\n# database: will use Grafana primary database.\n# redis: config like redis server e.g. `addr=127.0.0.1:6379,pool_size=100,db=0,ssl=false`. Only addr is required. ssl may be 'true', 'false', or 'insecure'.\n# memcache: 127.0.0.1:11211\n;connstr =\n\n#################################### Data proxy ###########################\n[dataproxy]\n\n# This enables data proxy logging, default is false\n;logging = false\n\n# How long the data proxy waits to read the headers of the response before timing out, default is 30 seconds.\n# This setting also applies to core backend HTTP data sources where query requests use an HTTP client with timeout set.\n;timeout = 30\n\n# How long the data proxy waits to establish a TCP connection before timing out, default is 10 seconds.\n;dialTimeout = 10\n\n# How many seconds the data proxy waits before sending a keepalive probe request.\n;keep_alive_seconds = 30\n\n# How many seconds the data proxy waits for a successful TLS Handshake before timing out.\n;tls_handshake_timeout_seconds = 10\n\n# How many seconds the data proxy will wait for a server's first response headers after\n# fully writing the request headers if the request has an \"Expect: 100-continue\"\n# header. A value of 0 will result in the body being sent immediately, without\n# waiting for the server to approve.\n;expect_continue_timeout_seconds = 1\n\n# Optionally limits the total number of connections per host, including connections in the dialing,\n# active, and idle states. On limit violation, dials will block.\n# A value of zero (0) means no limit.\n;max_conns_per_host = 0\n\n# The maximum number of idle connections that Grafana will keep alive.\n;max_idle_connections = 100\n\n# How many seconds the data proxy keeps an idle connection open before timing out.\n;idle_conn_timeout_seconds = 90\n\n# If enabled and user is not anonymous, data proxy will add X-Grafana-User header with username into the request, default is false.\n;send_user_header = false\n\n# Limit the amount of bytes that will be read/accepted from responses of outgoing HTTP requests.\n;response_limit = 0\n\n# Limits the number of rows that Grafana will process from SQL data sources.\n;row_limit = 1000000\n\n#################################### Analytics ####################################\n[analytics]\n# Server reporting, sends usage counters to stats.grafana.org every 24 hours.\n# No ip addresses are being tracked, only simple counters to track\n# running instances, dashboard and error counts. It is very helpful to us.\n# Change this option to false to disable reporting.\n;reporting_enabled = true\n\n# The name of the distributor of the Grafana instance. Ex hosted-grafana, grafana-labs\n;reporting_distributor = grafana-labs\n\n# Set to false to disable all checks to https://grafana.com\n# for new versions of grafana. The check is used\n# in some UI views to notify that a grafana update exists.\n# This option does not cause any auto updates, nor send any information\n# only a GET request to https://raw.githubusercontent.com/grafana/grafana/main/latest.json to get the latest version.\n;check_for_updates = true\n\n# Set to false to disable all checks to https://grafana.com\n# for new versions of plugins. The check is used\n# in some UI views to notify that a plugin update exists.\n# This option does not cause any auto updates, nor send any information\n# only a GET request to https://grafana.com to get the latest versions.\n;check_for_plugin_updates = true\n\n# Google Analytics universal tracking code, only enabled if you specify an id here\n;google_analytics_ua_id =\n\n# Google Tag Manager ID, only enabled if you specify an id here\n;google_tag_manager_id =\n\n# Rudderstack write key, enabled only if rudderstack_data_plane_url is also set\n;rudderstack_write_key =\n\n# Rudderstack data plane url, enabled only if rudderstack_write_key is also set\n;rudderstack_data_plane_url =\n\n# Rudderstack SDK url, optional, only valid if rudderstack_write_key and rudderstack_data_plane_url is also set\n;rudderstack_sdk_url =\n\n# Rudderstack Config url, optional, used by Rudderstack SDK to fetch source config\n;rudderstack_config_url =\n\n# Controls if the UI contains any links to user feedback forms\n;feedback_links_enabled = true\n\n#################################### Security ####################################\n[security]\n# disable creation of admin user on first start of grafana\n;disable_initial_admin_creation = false\n\n# default admin user, created on startup\n;admin_user = admin\n\n# default admin password, can be changed before first start of grafana,  or in profile settings\n;admin_password = admin\n\n# used for signing\n;secret_key = SW2YcwTIb9zpOOhoPsMm\n\n# current key provider used for envelope encryption, default to static value specified by secret_key\n;encryption_provider = secretKey.v1\n\n# list of configured key providers, space separated (Enterprise only): e.g., awskms.v1 azurekv.v1\n;available_encryption_providers =\n\n# disable gravatar profile images\n;disable_gravatar = false\n\n# data source proxy whitelist (ip_or_domain:port separated by spaces)\n;data_source_proxy_whitelist =\n\n# disable protection against brute force login attempts\n;disable_brute_force_login_protection = false\n\n# set to true if you host Grafana behind HTTPS. default is false.\n;cookie_secure = false\n\n# set cookie SameSite attribute. defaults to `lax`. can be set to \"lax\", \"strict\", \"none\" and \"disabled\"\n;cookie_samesite = lax\n\n# set to true if you want to allow browsers to render Grafana in a <frame>, <iframe>, <embed> or <object>. default is false.\n;allow_embedding = false\n\n# Set to true if you want to enable http strict transport security (HSTS) response header.\n# HSTS tells browsers that the site should only be accessed using HTTPS.\n;strict_transport_security = false\n\n# Sets how long a browser should cache HSTS. Only applied if strict_transport_security is enabled.\n;strict_transport_security_max_age_seconds = 86400\n\n# Set to true if to enable HSTS preloading option. Only applied if strict_transport_security is enabled.\n;strict_transport_security_preload = false\n\n# Set to true if to enable the HSTS includeSubDomains option. Only applied if strict_transport_security is enabled.\n;strict_transport_security_subdomains = false\n\n# Set to true to enable the X-Content-Type-Options response header.\n# The X-Content-Type-Options response HTTP header is a marker used by the server to indicate that the MIME types advertised\n# in the Content-Type headers should not be changed and be followed.\n;x_content_type_options = true\n\n# Set to true to enable the X-XSS-Protection header, which tells browsers to stop pages from loading\n# when they detect reflected cross-site scripting (XSS) attacks.\n;x_xss_protection = true\n\n# Enable adding the Content-Security-Policy header to your requests.\n# CSP allows to control resources the user agent is allowed to load and helps prevent XSS attacks.\n;content_security_policy = false\n\n# Set Content Security Policy template used when adding the Content-Security-Policy header to your requests.\n# $NONCE in the template includes a random nonce.\n# $ROOT_PATH is server.root_url without the protocol.\n;content_security_policy_template = \"\"\"script-src 'self' 'unsafe-eval' 'unsafe-inline' 'strict-dynamic' $NONCE;object-src 'none';font-src 'self';style-src 'self' 'unsafe-inline' blob:;img-src * data:;base-uri 'self';connect-src 'self' grafana.com ws://$ROOT_PATH wss://$ROOT_PATH;manifest-src 'self';media-src 'none';form-action 'self';\"\"\"\n\n# Controls if old angular plugins are supported or not. This will be disabled by default in future release\n;angular_support_enabled = true\n\n[security.encryption]\n# Defines the time-to-live (TTL) for decrypted data encryption keys stored in memory (cache).\n# Please note that small values may cause performance issues due to a high frequency decryption operations.\n;data_keys_cache_ttl = 15m\n\n# Defines the frequency of data encryption keys cache cleanup interval.\n# On every interval, decrypted data encryption keys that reached the TTL are removed from the cache.\n;data_keys_cache_cleanup_interval = 1m\n\n#################################### Snapshots ###########################\n[snapshots]\n# snapshot sharing options\n;external_enabled = true\n;external_snapshot_url = https://snapshots.raintank.io\n;external_snapshot_name = Publish to snapshots.raintank.io\n\n# Set to true to enable this Grafana instance act as an external snapshot server and allow unauthenticated requests for\n# creating and deleting snapshots.\n;public_mode = false\n\n# remove expired snapshot\n;snapshot_remove_expired = true\n\n#################################### Dashboards History ##################\n[dashboards]\n# Number dashboard versions to keep (per dashboard). Default: 20, Minimum: 1\n;versions_to_keep = 20\n\n# Minimum dashboard refresh interval. When set, this will restrict users to set the refresh interval of a dashboard lower than given interval. Per default this is 5 seconds.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\n;min_refresh_interval = 5s\n\n# Path to the default home dashboard. If this value is empty, then Grafana uses StaticRootPath + \"dashboards/home.json\"\n;default_home_dashboard_path =\n\n#################################### Users ###############################\n[users]\n# disable user signup / registration\n;allow_sign_up = true\n\n# Allow non admin users to create organizations\n;allow_org_create = true\n\n# Set to true to automatically assign new users to the default organization (id 1)\n;auto_assign_org = true\n\n# Set this value to automatically add new users to the provided organization (if auto_assign_org above is set to true)\n;auto_assign_org_id = 1\n\n# Default role new users will be automatically assigned (if disabled above is set to true)\n;auto_assign_org_role = Viewer\n\n# Require email validation before sign up completes\n;verify_email_enabled = false\n\n# Background text for the user field on the login page\n;login_hint = email or username\n;password_hint = password\n\n# Default UI theme (\"dark\" or \"light\")\n;default_theme = dark\n\n# Path to a custom home page. Users are only redirected to this if the default home dashboard is used. It should match a frontend route and contain a leading slash.\n; home_page =\n\n# External user management, these options affect the organization users view\n;external_manage_link_url =\n;external_manage_link_name =\n;external_manage_info =\n\n# Viewers can edit/inspect dashboard settings in the browser. But not save the dashboard.\n;viewers_can_edit = false\n\n# Editors can administrate dashboard, folders and teams they create\n;editors_can_admin = false\n\n# The duration in time a user invitation remains valid before expiring. This setting should be expressed as a duration. Examples: 6h (hours), 2d (days), 1w (week). Default is 24h (24 hours). The minimum supported duration is 15m (15 minutes).\n;user_invite_max_lifetime_duration = 24h\n\n# Enter a comma-separated list of users login to hide them in the Grafana UI. These users are shown to Grafana admins and themselves.\n; hidden_users =\n\n[auth]\n# Login cookie name\n;login_cookie_name = grafana_session\n\n# The maximum lifetime (duration) an authenticated user can be inactive before being required to login at next visit. Default is 7 days (7d). This setting should be expressed as a duration, e.g. 5m (minutes), 6h (hours), 10d (days), 2w (weeks), 1M (month). The lifetime resets at each successful token rotation.\n;login_maximum_inactive_lifetime_duration =\n\n# The maximum lifetime (duration) an authenticated user can be logged in since login time before being required to login. Default is 30 days (30d). This setting should be expressed as a duration, e.g. 5m (minutes), 6h (hours), 10d (days), 2w (weeks), 1M (month).\n;login_maximum_lifetime_duration =\n\n# How often should auth tokens be rotated for authenticated users when being active. The default is each 10 minutes.\n;token_rotation_interval_minutes = 10\n\n# Set to true to disable (hide) the login form, useful if you use OAuth, defaults to false\ndisable_login_form = true \n\n# Set to true to disable the sign out link in the side menu. Useful if you use auth.proxy or auth.jwt, defaults to false\n;disable_signout_menu = false\n\n# URL to redirect the user to after sign out\n;signout_redirect_url =\n\n# Set to true to attempt login with OAuth automatically, skipping the login screen.\n# This setting is ignored if multiple OAuth providers are configured.\n;oauth_auto_login = false\n\n# OAuth state max age cookie duration in seconds. Defaults to 600 seconds.\n;oauth_state_cookie_max_age = 600\n\n# Skip forced assignment of OrgID 1 or 'auto_assign_org_id' for social logins\n;oauth_skip_org_role_update_sync = false\n\n# limit of api_key seconds to live before expiration\n;api_key_max_seconds_to_live = -1\n\n# Set to true to enable SigV4 authentication option for HTTP-based datasources.\n;sigv4_auth_enabled = false\n\n# Set to true to enable verbose logging of SigV4 request signing\n;sigv4_verbose_logging = false\n\n#################################### Anonymous Auth ######################\n[auth.anonymous]\n# enable anonymous access\nenabled = true \n\n# specify organization name that should be used for unauthenticated users\norg_name = Main Org.\n\n# specify role for unauthenticated users\norg_role = Admin \n\n# mask the Grafana version number for unauthenticated users\n;hide_version = false\n\n#################################### GitHub Auth ##########################\n[auth.github]\n;enabled = false\n;allow_sign_up = true\n;client_id = some_id\n;client_secret = some_secret\n;scopes = user:email,read:org\n;auth_url = https://github.com/login/oauth/authorize\n;token_url = https://github.com/login/oauth/access_token\n;api_url = https://api.github.com/user\n;allowed_domains =\n;team_ids =\n;allowed_organizations =\n\n#################################### GitLab Auth #########################\n[auth.gitlab]\n;enabled = false\n;allow_sign_up = true\n;client_id = some_id\n;client_secret = some_secret\n;scopes = api\n;auth_url = https://gitlab.com/oauth/authorize\n;token_url = https://gitlab.com/oauth/token\n;api_url = https://gitlab.com/api/v4\n;allowed_domains =\n;allowed_groups =\n\n#################################### Google Auth ##########################\n[auth.google]\n;enabled = false\n;allow_sign_up = true\n;client_id = some_client_id\n;client_secret = some_client_secret\n;scopes = https://www.googleapis.com/auth/userinfo.profile https://www.googleapis.com/auth/userinfo.email\n;auth_url = https://accounts.google.com/o/oauth2/auth\n;token_url = https://accounts.google.com/o/oauth2/token\n;api_url = https://www.googleapis.com/oauth2/v1/userinfo\n;allowed_domains =\n;hosted_domain =\n\n#################################### Grafana.com Auth ####################\n[auth.grafana_com]\n;enabled = false\n;allow_sign_up = true\n;client_id = some_id\n;client_secret = some_secret\n;scopes = user:email\n;allowed_organizations =\n\n#################################### Azure AD OAuth #######################\n[auth.azuread]\n;name = Azure AD\n;enabled = false\n;allow_sign_up = true\n;client_id = some_client_id\n;client_secret = some_client_secret\n;scopes = openid email profile\n;auth_url = https://login.microsoftonline.com/<tenant-id>/oauth2/v2.0/authorize\n;token_url = https://login.microsoftonline.com/<tenant-id>/oauth2/v2.0/token\n;allowed_domains =\n;allowed_groups =\n;role_attribute_strict = false\n\n#################################### Okta OAuth #######################\n[auth.okta]\n;name = Okta\n;enabled = false\n;allow_sign_up = true\n;client_id = some_id\n;client_secret = some_secret\n;scopes = openid profile email groups\n;auth_url = https://<tenant-id>.okta.com/oauth2/v1/authorize\n;token_url = https://<tenant-id>.okta.com/oauth2/v1/token\n;api_url = https://<tenant-id>.okta.com/oauth2/v1/userinfo\n;allowed_domains =\n;allowed_groups =\n;role_attribute_path =\n;role_attribute_strict = false\n\n#################################### Generic OAuth ##########################\n[auth.generic_oauth]\n;enabled = false\n;name = OAuth\n;allow_sign_up = true\n;client_id = some_id\n;client_secret = some_secret\n;scopes = user:email,read:org\n;empty_scopes = false\n;email_attribute_name = email:primary\n;email_attribute_path =\n;login_attribute_path =\n;name_attribute_path =\n;id_token_attribute_name =\n;auth_url = https://foo.bar/login/oauth/authorize\n;token_url = https://foo.bar/login/oauth/access_token\n;api_url = https://foo.bar/user\n;teams_url =\n;allowed_domains =\n;team_ids =\n;allowed_organizations =\n;role_attribute_path =\n;role_attribute_strict = false\n;groups_attribute_path =\n;team_ids_attribute_path =\n;tls_skip_verify_insecure = false\n;tls_client_cert =\n;tls_client_key =\n;tls_client_ca =\n;use_pkce = false\n\n#################################### Basic Auth ##########################\n[auth.basic]\n;enabled = true\n\n#################################### Auth Proxy ##########################\n[auth.proxy]\n;enabled = false\n;header_name = X-WEBAUTH-USER\n;header_property = username\n;auto_sign_up = true\n;sync_ttl = 60\n;whitelist = 192.168.1.1, 192.168.2.1\n;headers = Email:X-User-Email, Name:X-User-Name\n# Non-ASCII strings in header values are encoded using quoted-printable encoding\n;headers_encoded = false\n# Read the auth proxy docs for details on what the setting below enables\n;enable_login_token = false\n\n#################################### Auth JWT ##########################\n[auth.jwt]\n;enabled = true\n;header_name = X-JWT-Assertion\n;email_claim = sub\n;username_claim = sub\n;jwk_set_url = https://foo.bar/.well-known/jwks.json\n;jwk_set_file = /path/to/jwks.json\n;cache_ttl = 60m\n;expected_claims = {\"aud\": [\"foo\", \"bar\"]}\n;key_file = /path/to/key/file\n;auto_sign_up = false\n\n#################################### Auth LDAP ##########################\n[auth.ldap]\n;enabled = false\n;config_file = /etc/grafana/ldap.toml\n;allow_sign_up = true\n\n# LDAP background sync (Enterprise only)\n# At 1 am every day\n;sync_cron = \"0 1 * * *\"\n;active_sync_enabled = true\n\n#################################### AWS ###########################\n[aws]\n# Enter a comma-separated list of allowed AWS authentication providers.\n# Options are: default (AWS SDK Default), keys (Access && secret key), credentials (Credentials field), ec2_iam_role (EC2 IAM Role)\n; allowed_auth_providers = default,keys,credentials\n\n# Allow AWS users to assume a role using temporary security credentials.\n# If true, assume role will be enabled for all AWS authentication providers that are specified in aws_auth_providers\n; assume_role_enabled = true\n\n#################################### Azure ###############################\n[azure]\n# Azure cloud environment where Grafana is hosted\n# Possible values are AzureCloud, AzureChinaCloud, AzureUSGovernment and AzureGermanCloud\n# Default value is AzureCloud (i.e. public cloud)\n;cloud = AzureCloud\n\n# Specifies whether Grafana hosted in Azure service with Managed Identity configured (e.g. Azure Virtual Machines instance)\n# If enabled, the managed identity can be used for authentication of Grafana in Azure services\n# Disabled by default, needs to be explicitly enabled\n;managed_identity_enabled = false\n\n# Client ID to use for user-assigned managed identity\n# Should be set for user-assigned identity and should be empty for system-assigned identity\n;managed_identity_client_id =\n\n#################################### Role-based Access Control ###########\n[rbac]\n;enabled = true\n# If enabled, cache permissions in a in memory cache (Enterprise only)\n;permission_cache = true\n#################################### SMTP / Emailing ##########################\n[smtp]\n;enabled = false\n;host = localhost:25\n;user =\n# If the password contains # or ; you have to wrap it with triple quotes. Ex \"\"\"#password;\"\"\"\n;password =\n;cert_file =\n;key_file =\n;skip_verify = false\n;from_address = admin@grafana.localhost\n;from_name = Grafana\n# EHLO identity in SMTP dialog (defaults to instance_name)\n;ehlo_identity = dashboard.example.com\n# SMTP startTLS policy (defaults to 'OpportunisticStartTLS')\n;startTLS_policy = NoStartTLS\n\n[emails]\n;welcome_email_on_sign_up = false\n;templates_pattern = emails/*.html, emails/*.txt\n;content_types = text/html\n\n#################################### Logging ##########################\n[log]\n# Either \"console\", \"file\", \"syslog\". Default is console and  file\n# Use space to separate multiple modes, e.g. \"console file\"\n;mode = console file\n\n# Either \"debug\", \"info\", \"warn\", \"error\", \"critical\", default is \"info\"\n;level = info\n\n# optional settings to set different levels for specific loggers. Ex filters = sqlstore:debug\n;filters =\n\n# For \"console\" mode only\n[log.console]\n;level =\n\n# log line format, valid options are text, console and json\n;format = console\n\n# For \"file\" mode only\n[log.file]\n;level =\n\n# log line format, valid options are text, console and json\n;format = text\n\n# This enables automated log rotate(switch of following options), default is true\n;log_rotate = true\n\n# Max line number of single file, default is 1000000\n;max_lines = 1000000\n\n# Max size shift of single file, default is 28 means 1 << 28, 256MB\n;max_size_shift = 28\n\n# Segment log daily, default is true\n;daily_rotate = true\n\n# Expired days of log file(delete after max days), default is 7\n;max_days = 7\n\n[log.syslog]\n;level =\n\n# log line format, valid options are text, console and json\n;format = text\n\n# Syslog network type and address. This can be udp, tcp, or unix. If left blank, the default unix endpoints will be used.\n;network =\n;address =\n\n# Syslog facility. user, daemon and local0 through local7 are valid.\n;facility =\n\n# Syslog tag. By default, the process' argv[0] is used.\n;tag =\n\n[log.frontend]\n# Should Sentry javascript agent be initialized\n;enabled = false\n\n# Sentry DSN if you want to send events to Sentry.\n;sentry_dsn =\n\n# Custom HTTP endpoint to send events captured by the Sentry agent to. Default will log the events to stdout.\n;custom_endpoint = /log\n\n# Rate of events to be reported between 0 (none) and 1 (all), float\n;sample_rate = 1.0\n\n# Requests per second limit enforced an extended period, for Grafana backend log ingestion endpoint (/log).\n;log_endpoint_requests_per_second_limit = 3\n\n# Max requests accepted per short interval of time for Grafana backend log ingestion endpoint (/log).\n;log_endpoint_burst_limit = 15\n\n#################################### Usage Quotas ########################\n[quota]\n; enabled = false\n\n#### set quotas to -1 to make unlimited. ####\n# limit number of users per Org.\n; org_user = 10\n\n# limit number of dashboards per Org.\n; org_dashboard = 100\n\n# limit number of data_sources per Org.\n; org_data_source = 10\n\n# limit number of api_keys per Org.\n; org_api_key = 10\n\n# limit number of alerts per Org.\n;org_alert_rule = 100\n\n# limit number of orgs a user can create.\n; user_org = 10\n\n# Global limit of users.\n; global_user = -1\n\n# global limit of orgs.\n; global_org = -1\n\n# global limit of dashboards\n; global_dashboard = -1\n\n# global limit of api_keys\n; global_api_key = -1\n\n# global limit on number of logged in users.\n; global_session = -1\n\n# global limit of alerts\n;global_alert_rule = -1\n\n#################################### Unified Alerting ####################\n[unified_alerting]\n#Enable the Unified Alerting sub-system and interface. When enabled we'll migrate all of your alert rules and notification channels to the new system. New alert rules will be created and your notification channels will be converted into an Alertmanager configuration. Previous data is preserved to enable backwards compatibility but new data is removed.```\n;enabled = true\n\n# Comma-separated list of organization IDs for which to disable unified alerting. Only supported if unified alerting is enabled.\n;disabled_orgs =\n\n# Specify the frequency of polling for admin config changes.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\n;admin_config_poll_interval = 60s\n\n# Specify the frequency of polling for Alertmanager config changes.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\n;alertmanager_config_poll_interval = 60s\n\n# Listen address/hostname and port to receive unified alerting messages for other Grafana instances. The port is used for both TCP and UDP. It is assumed other Grafana instances are also running on the same port. The default value is `0.0.0.0:9094`.\n;ha_listen_address = \"0.0.0.0:9094\"\n\n# Listen address/hostname and port to receive unified alerting messages for other Grafana instances. The port is used for both TCP and UDP. It is assumed other Grafana instances are also running on the same port. The default value is `0.0.0.0:9094`.\n;ha_advertise_address = \"\"\n\n# Comma-separated list of initial instances (in a format of host:port) that will form the HA cluster. Configuring this setting will enable High Availability mode for alerting.\n;ha_peers = \"\"\n\n# Time to wait for an instance to send a notification via the Alertmanager. In HA, each Grafana instance will\n# be assigned a position (e.g. 0, 1). We then multiply this position with the timeout to indicate how long should\n# each instance wait before sending the notification to take into account replication lag.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\n;ha_peer_timeout = \"15s\"\n\n# The interval between sending gossip messages. By lowering this value (more frequent) gossip messages are propagated\n# across cluster more quickly at the expense of increased bandwidth usage.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\n;ha_gossip_interval = \"200ms\"\n\n# The interval between gossip full state syncs. Setting this interval lower (more frequent) will increase convergence speeds\n# across larger clusters at the expense of increased bandwidth usage.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\n;ha_push_pull_interval = \"60s\"\n\n# Enable or disable alerting rule execution. The alerting UI remains visible. This option has a legacy version in the `[alerting]` section that takes precedence.\n;execute_alerts = true\n\n# Alert evaluation timeout when fetching data from the datasource. This option has a legacy version in the `[alerting]` section that takes precedence.\n# The timeout string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\n;evaluation_timeout = 30s\n\n# Number of times we'll attempt to evaluate an alert rule before giving up on that evaluation. This option has a legacy version in the `[alerting]` section that takes precedence.\n;max_attempts = 3\n\n# Minimum interval to enforce between rule evaluations. Rules will be adjusted if they are less than this value  or if they are not multiple of the scheduler interval (10s). Higher values can help with resource management as we'll schedule fewer evaluations over time. This option has a legacy version in the `[alerting]` section that takes precedence.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\n;min_interval = 10s\n\n#################################### Alerting ############################\n[alerting]\n# Disable legacy alerting engine & UI features\n;enabled = false\n\n# Makes it possible to turn off alert execution but alerting UI is visible\n;execute_alerts = true\n\n# Default setting for new alert rules. Defaults to categorize error and timeouts as alerting. (alerting, keep_state)\n;error_or_timeout = alerting\n\n# Default setting for how Grafana handles nodata or null values in alerting. (alerting, no_data, keep_state, ok)\n;nodata_or_nullvalues = no_data\n\n# Alert notifications can include images, but rendering many images at the same time can overload the server\n# This limit will protect the server from render overloading and make sure notifications are sent out quickly\n;concurrent_render_limit = 5\n\n# Default setting for alert calculation timeout. Default value is 30\n;evaluation_timeout_seconds = 30\n\n# Default setting for alert notification timeout. Default value is 30\n;notification_timeout_seconds = 30\n\n# Default setting for max attempts to sending alert notifications. Default value is 3\n;max_attempts = 3\n\n# Makes it possible to enforce a minimal interval between evaluations, to reduce load on the backend\n;min_interval_seconds = 1\n\n# Configures for how long alert annotations are stored. Default is 0, which keeps them forever.\n# This setting should be expressed as a duration. Examples: 6h (hours), 10d (days), 2w (weeks), 1M (month).\n;max_annotation_age =\n\n# Configures max number of alert annotations that Grafana stores. Default value is 0, which keeps all alert annotations.\n;max_annotations_to_keep =\n\n#################################### Annotations #########################\n[annotations]\n# Configures the batch size for the annotation clean-up job. This setting is used for dashboard, API, and alert annotations.\n;cleanupjob_batchsize = 100\n\n[annotations.dashboard]\n# Dashboard annotations means that annotations are associated with the dashboard they are created on.\n\n# Configures how long dashboard annotations are stored. Default is 0, which keeps them forever.\n# This setting should be expressed as a duration. Examples: 6h (hours), 10d (days), 2w (weeks), 1M (month).\n;max_age =\n\n# Configures max number of dashboard annotations that Grafana stores. Default value is 0, which keeps all dashboard annotations.\n;max_annotations_to_keep =\n\n[annotations.api]\n# API annotations means that the annotations have been created using the API without any\n# association with a dashboard.\n\n# Configures how long Grafana stores API annotations. Default is 0, which keeps them forever.\n# This setting should be expressed as a duration. Examples: 6h (hours), 10d (days), 2w (weeks), 1M (month).\n;max_age =\n\n# Configures max number of API annotations that Grafana keeps. Default value is 0, which keeps all API annotations.\n;max_annotations_to_keep =\n\n#################################### Explore #############################\n[explore]\n# Enable the Explore section\n;enabled = true\n\n#################################### Help #############################\n[help]\n# Enable the Help section\n;enabled = true\n\n#################################### Profile #############################\n[profile]\n# Enable the Profile section\n;enabled = true\n\n#################################### Query History #############################\n[query_history]\n# Enable the Query history\n;enabled = true\n\n#################################### Internal Grafana Metrics ##########################\n# Metrics available at HTTP URL /metrics and /metrics/plugins/:pluginId\n[metrics]\n# Disable / Enable internal metrics\n;enabled           = true\n# Graphite Publish interval\n;interval_seconds  = 10\n# Disable total stats (stat_totals_*) metrics to be generated\n;disable_total_stats = false\n\n#If both are set, basic auth will be required for the metrics endpoints.\n; basic_auth_username =\n; basic_auth_password =\n\n# Metrics environment info adds dimensions to the `grafana_environment_info` metric, which\n# can expose more information about the Grafana instance.\n[metrics.environment_info]\n#exampleLabel1 = exampleValue1\n#exampleLabel2 = exampleValue2\n\n# Send internal metrics to Graphite\n[metrics.graphite]\n# Enable by setting the address setting (ex localhost:2003)\n;address =\n;prefix = prod.grafana.%(instance_name)s.\n\n#################################### Grafana.com integration  ##########################\n# Url used to import dashboards directly from Grafana.com\n[grafana_com]\n;url = https://grafana.com\n\n#################################### Distributed tracing ############\n# Opentracing is deprecated use opentelemetry instead\n[tracing.jaeger]\n# Enable by setting the address sending traces to jaeger (ex localhost:6831)\n;address = localhost:6831\n# Tag that will always be included in when creating new spans. ex (tag1:value1,tag2:value2)\n;always_included_tag = tag1:value1\n# Type specifies the type of the sampler: const, probabilistic, rateLimiting, or remote\n;sampler_type = const\n# jaeger samplerconfig param\n# for \"const\" sampler, 0 or 1 for always false/true respectively\n# for \"probabilistic\" sampler, a probability between 0 and 1\n# for \"rateLimiting\" sampler, the number of spans per second\n# for \"remote\" sampler, param is the same as for \"probabilistic\"\n# and indicates the initial sampling rate before the actual one\n# is received from the mothership\n;sampler_param = 1\n# sampling_server_url is the URL of a sampling manager providing a sampling strategy.\n;sampling_server_url =\n# Whether or not to use Zipkin propagation (x-b3- HTTP headers).\n;zipkin_propagation = false\n# Setting this to true disables shared RPC spans.\n# Not disabling is the most common setting when using Zipkin elsewhere in your infrastructure.\n;disable_shared_zipkin_spans = false\n\n[tracing.opentelemetry.jaeger]\n# jaeger destination (ex http://localhost:14268/api/traces)\n; address = http://localhost:14268/api/traces\n# Propagation specifies the text map propagation format: w3c, jaeger\n; propagation = jaeger\n\n# This is a configuration for OTLP exporter with GRPC protocol\n[tracing.opentelemetry.otlp]\n# otlp destination (ex localhost:4317)\n; address = localhost:4317\n# Propagation specifies the text map propagation format: w3c, jaeger\n; propagation = w3c\n\n#################################### External image storage ##########################\n[external_image_storage]\n# Used for uploading images to public servers so they can be included in slack/email messages.\n# you can choose between (s3, webdav, gcs, azure_blob, local)\n;provider =\n\n[external_image_storage.s3]\n;endpoint =\n;path_style_access =\n;bucket =\n;region =\n;path =\n;access_key =\n;secret_key =\n\n[external_image_storage.webdav]\n;url =\n;public_url =\n;username =\n;password =\n\n[external_image_storage.gcs]\n;key_file =\n;bucket =\n;path =\n\n[external_image_storage.azure_blob]\n;account_name =\n;account_key =\n;container_name =\n\n[external_image_storage.local]\n# does not require any configuration\n\n[rendering]\n# Options to configure a remote HTTP image rendering service, e.g. using https://github.com/grafana/grafana-image-renderer.\n# URL to a remote HTTP image renderer service, e.g. http://localhost:8081/render, will enable Grafana to render panels and dashboards to PNG-images using HTTP requests to an external service.\n;server_url =\n# If the remote HTTP image renderer service runs on a different server than the Grafana server you may have to configure this to a URL where Grafana is reachable, e.g. http://grafana.domain/.\n;callback_url =\n# Concurrent render request limit affects when the /render HTTP endpoint is used. Rendering many images at the same time can overload the server,\n# which this setting can help protect against by only allowing a certain amount of concurrent requests.\n;concurrent_render_request_limit = 30\n\n[panels]\n# If set to true Grafana will allow script tags in text panels. Not recommended as it enable XSS vulnerabilities.\n;disable_sanitize_html = false\n\n[plugins]\n;enable_alpha = false\n;app_tls_skip_verify_insecure = false\n# Enter a comma-separated list of plugin identifiers to identify plugins to load even if they are unsigned. Plugins with modified signatures are never loaded.\n;allow_loading_unsigned_plugins =\n# Enable or disable installing / uninstalling / updating plugins directly from within Grafana.\n;plugin_admin_enabled = false\n;plugin_admin_external_manage_enabled = false\n;plugin_catalog_url = https://grafana.com/grafana/plugins/\n# Enter a comma-separated list of plugin identifiers to hide in the plugin catalog.\n;plugin_catalog_hidden_plugins =\n\n#################################### Grafana Live ##########################################\n[live]\n# max_connections to Grafana Live WebSocket endpoint per Grafana server instance. See Grafana Live docs\n# if you are planning to make it higher than default 100 since this can require some OS and infrastructure\n# tuning. 0 disables Live, -1 means unlimited connections.\n;max_connections = 100\n\n# allowed_origins is a comma-separated list of origins that can establish connection with Grafana Live.\n# If not set then origin will be matched over root_url. Supports wildcard symbol \"*\".\n;allowed_origins =\n\n# engine defines an HA (high availability) engine to use for Grafana Live. By default no engine used - in\n# this case Live features work only on a single Grafana server. Available options: \"redis\".\n# Setting ha_engine is an EXPERIMENTAL feature.\n;ha_engine =\n\n# ha_engine_address sets a connection address for Live HA engine. Depending on engine type address format can differ.\n# For now we only support Redis connection address in \"host:port\" format.\n# This option is EXPERIMENTAL.\n;ha_engine_address = \"127.0.0.1:6379\"\n\n#################################### Grafana Image Renderer Plugin ##########################\n[plugin.grafana-image-renderer]\n# Instruct headless browser instance to use a default timezone when not provided by Grafana, e.g. when rendering panel image of alert.\n# See ICUs metaZones.txt (https://cs.chromium.org/chromium/src/third_party/icu/source/data/misc/metaZones.txt) for a list of supported\n# timezone IDs. Fallbacks to TZ environment variable if not set.\n;rendering_timezone =\n\n# Instruct headless browser instance to use a default language when not provided by Grafana, e.g. when rendering panel image of alert.\n# Please refer to the HTTP header Accept-Language to understand how to format this value, e.g. 'fr-CH, fr;q=0.9, en;q=0.8, de;q=0.7, *;q=0.5'.\n;rendering_language =\n\n# Instruct headless browser instance to use a default device scale factor when not provided by Grafana, e.g. when rendering panel image of alert.\n# Default is 1. Using a higher value will produce more detailed images (higher DPI), but will require more disk space to store an image.\n;rendering_viewport_device_scale_factor =\n\n# Instruct headless browser instance whether to ignore HTTPS errors during navigation. Per default HTTPS errors are not ignored. Due to\n# the security risk it's not recommended to ignore HTTPS errors.\n;rendering_ignore_https_errors =\n\n# Instruct headless browser instance whether to capture and log verbose information when rendering an image. Default is false and will\n# only capture and log error messages. When enabled, debug messages are captured and logged as well.\n# For the verbose information to be included in the Grafana server log you have to adjust the rendering log level to debug, configure\n# [log].filter = rendering:debug.\n;rendering_verbose_logging =\n\n# Instruct headless browser instance whether to output its debug and error messages into running process of remote rendering service.\n# Default is false. This can be useful to enable (true) when troubleshooting.\n;rendering_dumpio =\n\n# Additional arguments to pass to the headless browser instance. Default is --no-sandbox. The list of Chromium flags can be found\n# here (https://peter.sh/experiments/chromium-command-line-switches/). Multiple arguments is separated with comma-character.\n;rendering_args =\n\n# You can configure the plugin to use a different browser binary instead of the pre-packaged version of Chromium.\n# Please note that this is not recommended, since you may encounter problems if the installed version of Chrome/Chromium is not\n# compatible with the plugin.\n;rendering_chrome_bin =\n\n# Instruct how headless browser instances are created. Default is 'default' and will create a new browser instance on each request.\n# Mode 'clustered' will make sure that only a maximum of browsers/incognito pages can execute concurrently.\n# Mode 'reusable' will have one browser instance and will create a new incognito page on each request.\n;rendering_mode =\n\n# When rendering_mode = clustered, you can instruct how many browsers or incognito pages can execute concurrently. Default is 'browser'\n# and will cluster using browser instances.\n# Mode 'context' will cluster using incognito pages.\n;rendering_clustering_mode =\n# When rendering_mode = clustered, you can define the maximum number of browser instances/incognito pages that can execute concurrently. Default is '5'.\n;rendering_clustering_max_concurrency =\n# When rendering_mode = clustered, you can specify the duration a rendering request can take before it will time out. Default is `30` seconds.\n;rendering_clustering_timeout =\n\n# Limit the maximum viewport width, height and device scale factor that can be requested.\n;rendering_viewport_max_width =\n;rendering_viewport_max_height =\n;rendering_viewport_max_device_scale_factor =\n\n# Change the listening host and port of the gRPC server. Default host is 127.0.0.1 and default port is 0 and will automatically assign\n# a port not in use.\n;grpc_host =\n;grpc_port =\n\n[enterprise]\n# Path to a valid Grafana Enterprise license.jwt file\n;license_path =\n\n[feature_toggles]\n# there are currently two ways to enable feature toggles in the `grafana.ini`.\n# you can either pass an array of feature you want to enable to the `enable` field or\n# configure each toggle by setting the name of the toggle to true/false. Toggles set to true/false\n# will take presidence over toggles in the `enable` list.\n\n;enable = feature1,feature2\n\n;feature1 = true\n;feature2 = false\n\n[date_formats]\n# For information on what formatting patterns that are supported https://momentjs.com/docs/#/displaying/\n\n# Default system date format used in time range picker and other places where full time is displayed\n;full_date = YYYY-MM-DD HH:mm:ss\n\n# Used by graph and other places where we only show small intervals\n;interval_second = HH:mm:ss\n;interval_minute = HH:mm\n;interval_hour = MM/DD HH:mm\n;interval_day = MM/DD\n;interval_month = YYYY-MM\n;interval_year = YYYY\n\n# Experimental feature\n;use_browser_locale = false\n\n# Default timezone for user preferences. Options are 'browser' for the browser local timezone or a timezone name from IANA Time Zone database, e.g. 'UTC' or 'Europe/Amsterdam' etc.\n;default_timezone = browser\n\n[expressions]\n# Enable or disable the expressions functionality.\n;enabled = true\n\n[geomap]\n# Set the JSON configuration for the default basemap\n;default_baselayer_config = `{\n;  \"type\": \"xyz\",\n;  \"config\": {\n;    \"attribution\": \"Open street map\",\n;    \"url\": \"https://tile.openstreetmap.org/{z}/{x}/{y}.png\"\n;  }\n;}`\n\n# Enable or disable loading other base map layers\n;enable_custom_baselayers = true\n"
kind: ConfigMap
metadata:
  annotations:
    use-subpath: "true"
  namespace: otel
  labels:
    io.kompose.service: grafana
  name: grafana-cm0
---
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: otel
  labels:
    io.kompose.service: grafana
  name: grafana-cm1
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: grafana
  name: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: grafana
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: grafana
    spec:
      containers:
        - image: grafana/grafana:9.1.0
          name: grafana
          ports:
            - containerPort: 3000
          resources:
            limits:
              memory: "78643200"
          volumeMounts:
            - mountPath: /etc/grafana/grafana.ini
              name: grafana-cm0
              subPath: grafana.ini
            - mountPath: /etc/grafana/provisioning
              name: grafana-cm1
      restartPolicy: Always
      volumes:
        - configMap:
            items:
              - key: grafana.ini
                path: grafana.ini
            name: grafana-cm0
          name: grafana-cm0
        - configMap:
            name: grafana-cm1
          name: grafana-cm1
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: grafana
  name: grafana
spec:
  ports:
    - name: "3000"
      port: 3000
      targetPort: 3000
  selector:
    io.kompose.service: grafana
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: jaeger
  name: jaeger
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: jaeger
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: jaeger
    spec:
      containers:
        - args:
            - --memory.max-traces
            - "10000"
            - --query.base-path
            - /jaeger/ui
            - --prometheus.server-url
            - http://prometheus:9090
          env:
            - name: COLLECTOR_OTLP_ENABLED
              value: "true"
            - name: METRICS_STORAGE_TYPE
              value: prometheus
          image: jaegertracing/all-in-one
          name: jaeger
          ports:
            - containerPort: 16686
            - containerPort: 4317
          resources:
            limits:
              memory: "314572800"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: jaeger
  name: jaeger
spec:
  ports:
    - name: "16686"
      port: 16686
      targetPort: 16686
    - name: "4317"
      port: 4317
      targetPort: 4317
  selector:
    io.kompose.service: jaeger
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: kafka
  name: kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: kafka
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: kafka
    spec:
      containers:
        - env:
            - name: KAFKA_ADVERTISED_LISTENERS
              value: PLAINTEXT://kafka-headless:9092
            - name: KAFKA_HEAP_OPTS
              value: -Xmx400m -Xms400m
            - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: kafka-headless
          image: ghcr.io/open-telemetry/demo:1.3.1-kafka
          livenessProbe:
            exec:
              command:
                - sh
                - -c
                - nc -z kafka-headless 9092
            failureThreshold: 10
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 10
          name: kafka
          resources:
            limits:
              memory: "786432e3"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: kafka-headless
  name: kafka-headless
spec:
  ports:
    - name: 'kafka'
      port: 9092
      targetPort: 9092
  selector:
    io.kompose.service: kafka
  clusterIP: None
  publishNotReadyAddresses: true
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: loadgenerator
  name: loadgenerator
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: loadgenerator
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: loadgenerator
    spec:
      containers:
        - env:
            - name: LOCUST_AUTOSTART
              value: "true"
            - name: LOCUST_HEADLESS
              value: "false"
            - name: LOCUST_HOST
              value: http://frontend:8080
            - name: LOCUST_USERS
              value: "10"
            - name: LOCUST_WEB_PORT
              value: "8089"
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4318/v1/traces
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: loadgenerator
            - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
              value: python
          image: ghcr.io/open-telemetry/demo:1.3.1-loadgenerator
          name: load-generator
          ports:
            - containerPort: 8089
          resources:
            limits:
              memory: "125829120"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: loadgenerator
  name: loadgenerator
spec:
  ports:
    - name: "8089"
      port: 8089
      targetPort: 8089
  selector:
    io.kompose.service: loadgenerator
status:
  loadBalancer: {}
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  namespace: otel
  name: opentelemetry-demo
spec:
  ingress:
    - from:
        - podSelector:
            matchLabels:
              io.kompose.network/opentelemetry-demo: "true"
  podSelector:
    matchLabels:
      io.kompose.network/opentelemetry-demo: "true"
---
apiVersion: v1
data:
  otelcol-config.yml: |
    # Copyright The OpenTelemetry Authors
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    receivers:
      otlp:
        protocols:
          grpc:
          http:
            cors:
              allowed_origins:
                - "http://*"
                - "https://*"

    exporters:
      otlp:
        endpoint: "jaeger:4317"
        tls:
          insecure: true
      logging:
      prometheus:
        endpoint: "localhost:9464"
        resource_to_telemetry_conversion:
          enabled: true
        enable_open_metrics: true
    processors:
      batch:
      spanmetrics:
        metrics_exporter: prometheus
      # temporary measure until description is fixed in .NET
      transform:
        metric_statements:
          - context: metric
            statements:
              - set(description, "Measures the duration of inbound HTTP requests") where name == "http.server.duration"

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [spanmetrics, batch]
          exporters: [logging, otlp]
        metrics:
          receivers: [otlp]
          processors: [transform, batch]
          exporters: [prometheus, logging]
kind: ConfigMap
metadata:
  annotations:
    use-subpath: "true"
  namespace: otel
  labels:
    io.kompose.service: otelcol
  name: otelcol-cm0
---
apiVersion: v1
data:
  otelcol-config-extras.yml: |
    # extra settings to be merged into OpenTelemetry Collector configuration
    # do not delete this file
kind: ConfigMap
metadata:
  annotations:
    use-subpath: "true"
  namespace: otel
  labels:
    io.kompose.service: otelcol
  name: otelcol-cm1
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: otelcol
  name: otelcol
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: otelcol
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: otelcol
    spec:
      containers:
        - args:
            - --config=/etc/otelcol-config.yml
            - --config=/etc/otelcol-config-extras.yml
          image: otel/opentelemetry-collector-contrib:0.70.0
          name: otel-col
          ports:
            - containerPort: 4317
            - containerPort: 4318
            - containerPort: 9464
            - containerPort: 8888
          resources:
            limits:
              memory: "131072e3"
          volumeMounts:
            - mountPath: /etc/otelcol-config.yml
              name: otelcol-cm0
              subPath: otelcol-config.yml
            - mountPath: /etc/otelcol-config-extras.yml
              name: otelcol-cm1
              subPath: otelcol-config-extras.yml
      restartPolicy: Always
      volumes:
        - configMap:
            items:
              - key: otelcol-config.yml
                path: otelcol-config.yml
            name: otelcol-cm0
          name: otelcol-cm0
        - configMap:
            items:
              - key: otelcol-config-extras.yml
                path: otelcol-config-extras.yml
            name: otelcol-cm1
          name: otelcol-cm1
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: otelcol
  name: otelcol
spec:
  ports:
    - name: "4317"
      port: 4317
      targetPort: 4317
    - name: "4318"
      port: 4318
      targetPort: 4318
    - name: "9464"
      port: 9464
      targetPort: 9464
    - name: "8888"
      port: 8888
      targetPort: 8888
  selector:
    io.kompose.service: otelcol
status:
  loadBalancer: {}
---
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: paymentservice
  name: paymentservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: paymentservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: paymentservice
    spec:
      containers:
        - env:
            - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: paymentservice
            - name: PAYMENT_SERVICE_PORT
              value: "50051"
          image: ghcr.io/open-telemetry/demo:1.3.1-paymentservice
          name: payment-service
          ports:
            - containerPort: 50051
          resources:
            limits:
              memory: "125829120"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: paymentservice
  name: paymentservice
spec:
  ports:
    - name: "50051"
      port: 50051
      targetPort: 50051
  selector:
    io.kompose.service: paymentservice
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: productcatalogservice
  name: productcatalogservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: productcatalogservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: productcatalogservice
    spec:
      containers:
        - env:
            - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
              value: featureflagservice:50053
            - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: productcatalogservice
            - name: PRODUCT_CATALOG_SERVICE_PORT
              value: "3550"
          image: ghcr.io/open-telemetry/demo:1.3.1-productcatalogservice
          name: product-catalog-service
          ports:
            - containerPort: 3550
          resources:
            limits:
              memory: "20971520"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: productcatalogservice
  name: productcatalogservice
spec:
  ports:
    - name: "3550"
      port: 3550
      targetPort: 3550
  selector:
    io.kompose.service: productcatalogservice
status:
  loadBalancer: {}
---
apiVersion: v1
data:
  prometheus-config.yaml: |
    # Copyright The OpenTelemetry Authors
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    global:
      evaluation_interval: 30s
      scrape_interval: 5s
    scrape_configs:
    - job_name: otel
      honor_labels: true
      static_configs:
      - targets:
        - 'otelcol:9464'
    - job_name: otel-collector
      static_configs:
      - targets:
        - 'otelcol:8888'
kind: ConfigMap
metadata:
  annotations:
    use-subpath: "true"
  namespace: otel
  labels:
    io.kompose.service: prometheus
  name: prometheus-cm0
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: prometheus
  name: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: prometheus
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: prometheus
    spec:
      containers:
        - args:
            - --web.console.templates=/etc/prometheus/consoles
            - --web.console.libraries=/etc/prometheus/console_libraries
            - --storage.tsdb.retention.time=1h
            - --config.file=/etc/prometheus/prometheus-config.yaml
            - --storage.tsdb.path=/prometheus
            - --web.enable-lifecycle
            - --web.route-prefix=/
            - --enable-feature=exemplar-storage
          image: quay.io/prometheus/prometheus:v2.34.0
          name: prometheus
          ports:
            - containerPort: 9090
          resources:
            limits:
              memory: "314572800"
          volumeMounts:
            - mountPath: /etc/prometheus/prometheus-config.yaml
              name: prometheus-cm0
              subPath: prometheus-config.yaml
      restartPolicy: Always
      volumes:
        - configMap:
            items:
              - key: prometheus-config.yaml
                path: prometheus-config.yaml
            name: prometheus-cm0
          name: prometheus-cm0
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: prometheus
  name: prometheus
spec:
  ports:
    - name: "9090"
      port: 9090
      targetPort: 9090
  selector:
    io.kompose.service: prometheus
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: quoteservice
  name: quoteservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: quoteservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: quoteservice
    spec:
      containers:
        - env:
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4318/v1/traces
            - name: OTEL_PHP_AUTOLOAD_ENABLED
              value: "true"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: quoteservice
            - name: QUOTE_SERVICE_PORT
              value: "8090"
          image: ghcr.io/open-telemetry/demo:1.3.1-quoteservice
          name: quote-service
          ports:
            - containerPort: 8090
          resources:
            limits:
              memory: "41943040"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: quoteservice
  name: quoteservice
spec:
  ports:
    - name: "8090"
      port: 8090
      targetPort: 8090
  selector:
    io.kompose.service: quoteservice
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: recommendationservice
  name: recommendationservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: recommendationservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: recommendationservice
    spec:
      containers:
        - env:
            - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
              value: featureflagservice:50053
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
              value: cumulative
            - name: OTEL_METRICS_EXPORTER
              value: otlp
            - name: OTEL_PYTHON_LOG_CORRELATION
              value: "true"
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: recommendationservice
            - name: OTEL_TRACES_EXPORTER
              value: otlp
            - name: PRODUCT_CATALOG_SERVICE_ADDR
              value: productcatalogservice:3550
            - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
              value: python
            - name: RECOMMENDATION_SERVICE_PORT
              value: "9001"
          image: ghcr.io/open-telemetry/demo:1.3.1-recommendationservice
          name: recommendation-service
          ports:
            - containerPort: 9001
          resources:
            limits:
              memory: "524288e3"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: recommendationservice
  name: recommendationservice
spec:
  ports:
    - name: "9001"
      port: 9001
      targetPort: 9001
  selector:
    io.kompose.service: recommendationservice
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: redis-cart
  name: redis-cart
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: redis-cart
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: redis-cart
    spec:
      containers:
        - image: redis:alpine
          name: redis-cart
          ports:
            - containerPort: 6379
          resources:
            limits:
              memory: "20971520"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: redis-cart
  name: redis-cart
spec:
  ports:
    - name: "6379"
      port: 6379
      targetPort: 6379
  selector:
    io.kompose.service: redis-cart
status:
  loadBalancer: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: shippingservice
  name: shippingservice
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: shippingservice
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
        kompose.version: 1.28.0 (c4137012e)
      namespace: otel
      labels:
        io.kompose.network/opentelemetry-demo: "true"
        io.kompose.service: shippingservice
    spec:
      containers:
        - env:
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://otelcol:4317
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.namespace=opentelemetry-demo
            - name: OTEL_SERVICE_NAME
              value: shippingservice
            - name: QUOTE_SERVICE_ADDR
              value: http://quoteservice:8090
            - name: SHIPPING_SERVICE_PORT
              value: "50050"
          image: ghcr.io/open-telemetry/demo:1.3.1-shippingservice
          name: shipping-service
          ports:
            - containerPort: 50050
          resources:
            limits:
              memory: "20971520"
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-resolved.yml --volumes=configMap -o otel-k8s-manifests/
    kompose.version: 1.28.0 (c4137012e)
  namespace: otel
  labels:
    io.kompose.service: shippingservice
  name: shippingservice
spec:
  ports:
    - name: "50050"
      port: 50050
      targetPort: 50050
  selector:
    io.kompose.service: shippingservice
status:
  loadBalancer: {}
